# Assistente de IA Avan√ßado para WhatsApp

## üìñ Sobre o Projeto

Este projeto implementa um assistente de IA conversacional avan√ßado e humanizado para intera√ß√£o via WhatsApp. Constru√≠do em Python com FastAPI, o assistente utiliza o framework **Agno** e o poder do **Google Gemini** para ir al√©m de um simples chatbot, incorporando funcionalidades de mem√≥ria persistente e a capacidade de consultar documentos espec√≠ficos (RAG).

O foco principal foi criar uma experi√™ncia de usu√°rio natural e fluida, simulando uma conversa humana atrav√©s de t√©cnicas como buffering de mensagens e envio de respostas parceladas.

---

## ‚ú® Principais Funcionalidades

-   üß† **Mem√≥ria Conversacional Persistente:** Utiliza **Redis** (ou opcionalmente arquivos locais) para lembrar o contexto de conversas anteriores, permitindo um di√°logo cont√≠nuo e coerente com cada usu√°rio.
-   üìö **Busca Aumentada por Recupera√ß√£o (RAG):** O assistente √© capaz de consultar uma base de conhecimento pr√≥pria (neste caso, um documento PDF vetorizado com **ChromaDB**) para responder a perguntas espec√≠ficas com base em fatos.
-   üó£Ô∏è **Intera√ß√£o Humanizada:**
    -   **Buffering de Entrada:** Agrupa mensagens enviadas rapidamente pelo usu√°rio antes de processar, esperando que ele termine de "digitar".
    -   **Respostas Parceladas:** Envia respostas longas em v√°rias mensagens curtas, com pausas, para simular uma digita√ß√£o natural.
-   üõ†Ô∏è **Arquitetura Baseada em Agentes e Ferramentas:** Usa uma arquitetura moderna onde o agente de IA pode decidir autonomamente quando usar "ferramentas" (como a busca em documentos) para melhor formular suas respostas.
-   üöÄ **Backend Ass√≠ncrono:** Constru√≠do com **FastAPI**, garantindo alta performance e a capacidade de lidar com m√∫ltiplas requisi√ß√µes simult√¢neas de forma eficiente.

---

## üèóÔ∏è Arquitetura do Projeto

O fluxo de uma mensagem atrav√©s do sistema √© o seguinte:

1.  **WhatsApp** ‚Üí O usu√°rio envia uma mensagem.
2.  **Evolution API** ‚Üí A mensagem √© recebida e encaminhada via Webhook.
3.  **FastAPI Endpoint** ‚Üí Nosso backend recebe a requisi√ß√£o.
4.  **Buffering (Redis)** ‚Üí A mensagem √© adicionada a um buffer. Uma tarefa em segundo plano aguarda para ver se mais mensagens chegam.
5.  **Agno Agent** ‚Üí Ap√≥s a espera, a mensagem (ou o conjunto de mensagens) √© enviada para o agente principal.
6.  **Decis√£o do Agente:**
    -   Se for uma pergunta geral, ele usa a **Mem√≥ria Conversacional** (Redis ou Arquivos) para obter o hist√≥rico e gerar uma resposta.
    -   Se for uma pergunta sobre o documento, ele ativa a **Ferramenta de RAG** para buscar o contexto relevante no **ChromaDB**.
7.  **LLM (Google Gemini)** ‚Üí O agente envia o prompt final (com contexto do RAG ou da mem√≥ria) para o Gemini.
8.  **Resposta Parcelada** ‚Üí A resposta gerada √© quebrada em partes e enviada de volta ao usu√°rio via **Evolution API**, simulando uma digita√ß√£o natural.

---

## üõ†Ô∏è Tecnologias Utilizadas

-   **Backend:** Python 3.11+
-   **Framework Web:** FastAPI
-   **Framework de IA:** Agno
-   **Bibliotecas de IA:** LangChain
-   **LLM:** Google Gemini (1.5 Flash)
-   **Mem√≥ria e Cache:** Redis
-   **RAG / Vector Store:** ChromaDB
-   **API WhatsApp:** Evolution API
-   **Ambiente de Desenvolvimento:** Docker

---

## ‚öôÔ∏è Configura√ß√£o e Instala√ß√£o

Siga os passos abaixo para configurar e rodar o projeto localmente.

### Pr√©-requisitos

-   Python 3.11 ou superior
-   Git
-   Docker e Docker Desktop (para rodar o Redis localmente)
-   Uma inst√¢ncia da [Evolution API](https://doc.evolution-api.com/v1/pt/get-started/introduction) configurada e rodando.
-   Acesso √† API do Google Gemini.

### Passos de Instala√ß√£o

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/Leozs00/agno_assistant.git](https://github.com/Leozs00/agno_assistant.git)
    cd agno_assistant
    ```

2.  **Crie e ative o ambiente virtual:**
    ```bash
    # Windows
    python -m venv .venv
    .\.venv\Scripts\activate

    # Linux / macOS
    python3 -m venv .venv
    source .venv/bin/activate
    ```

3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure as vari√°veis de ambiente:**
    -   Renomeie o arquivo `.env.example` para `.env` (se houver um no reposit√≥rio) ou crie um novo.
    -   Abra o arquivo `.env` e preencha todas as vari√°veis com suas chaves e credenciais (Google API Key, Evolution API, Redis, etc.).

5.  **Prepare a Base de Conhecimento (RAG):**
    -   Crie uma pasta chamada `data` na raiz do projeto.
    -   Coloque o documento PDF que voc√™ deseja usar como base de conhecimento dentro da pasta `data`.
    -   Renomeie o arquivo para `documento_de_conhecimento.pdf` (ou altere o caminho no arquivo `src/rag/ingest.py`).
    -   Execute o script de ingest√£o para criar o banco de dados de vetores:
        ```bash
        python -m src.rag.ingest
        ```
    -   Isso criar√° uma pasta `vector_store/` com os dados vetorizados.

### Executando a Aplica√ß√£o

1.  **Inicie o Redis com Docker:**
    ```bash
    docker start meu-redis-local
    ```
    *(Se for a primeira vez, use o comando `docker run -d --name meu-redis-local -p 6379:6379 redis`)*

2.  **Inicie o servidor FastAPI:**
    ```bash
    uvicorn src.main:app --reload
    ```
    O servidor estar√° rodando em `http://localhost:8000`.

3.  **Exponha seu servidor com ngrok:**
    Para que a Evolution API possa enviar webhooks para sua m√°quina local, use o ngrok.
    ```bash
    ngrok http 8000
    ```
    Copie a URL `https://...` gerada e configure-a como a URL de webhook na sua inst√¢ncia da Evolution API (n√£o se esque√ßa de adicionar `/webhook` ao final).

---

## üîó Links de Refer√™ncia

-   [Documenta√ß√£o do Agno Framework](https://docs.agno.com/)
-   [Documenta√ß√£o da Evolution API](https://doc.evolution-api.com/)
-   [Documenta√ß√£o do LangChain](https://python.langchain.com/)
-   [Google AI for Developers (Gemini)](https://ai.google.dev/)

---

## üë®‚Äçüíª Autor

-   **Leonardo** - [GitHub](https://github.com/Leozs00)
